---
layout: post
title: Getting started with neural networks
tags:
- How to study
---

## Who we are

We are a group of students from the department of [Informatics and Applied Mathematics](http://ysu.am/faculties/en/Informatics-and-Applied-Mathematics) at [Yerevan State University](http://ysu.am/main/en). In 2014, inspired by successes of neural nets in various fields, especially by [GoogLeNet's](http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/) excellent performance in ImageNet 2014, we decided to dive into the topic of neural networks. We study calculus, combinatorics, graph theory, algebra and many other topics in the university but we learn nothing about machine learning. Just a few students take some [ML courses](https://www.coursera.org/learn/machine-learning/home/info) from Coursera or elsewhere.

<!--more-->

## Choosing a video course
At the beginning of 2015 the [Student Scientific Society](http://ysu.am/sss/en) of the department initiated a project to study neural networks. We had to choose some video course on the internet, then watch and discuss the videos once per week in the university. We wanted a course that would cover everything from the very basics to convolutional networks and deep learning. We followed [Yoshua Bengio's](http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html) advice given during his [interview on Reddit](http://www.reddit.com/r/MachineLearning/comments/1ysry1/ama_yoshua_bengio) and chose [this excellent class](https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH) by [Hugo Larochelle](http://www.dmi.usherb.ca/~larocheh/index_en.html).

Hugo's lectures are really great. First two chapters teach the [basic structure](https://www.youtube.com/watch?v=SGZ6BttHMPw&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=1) of neural networks and describe the [backpropagation](https://www.youtube.com/watch?v=5adNQvSlF50&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=7) algorithm in details. We loved that he showed the derivation of the gradients of the loss function. Because of this, [Hrayr](https://github.com/Harhro94) managed to implement a simple multilayer neural net on his own. Next two chapters (which we skipped) talk about Conditional Random Fields. The fifth chapter introduces unsupervised learning with [Restricted Boltzmann Machines](https://www.youtube.com/watch?v=p4Vh_zMw-HQ&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=36). This was the hardest part for us, mainly because of our lack of knowledge in probabilistic graphical models. The sixth chapter on [autoencoders](https://www.youtube.com/watch?v=FzS3tMl4Nsc&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=44) is our favorite: the magic of denoising autoencoders is very surprising. Then there are chapters on [deep learning](https://www.youtube.com/watch?v=vXMpKYRhpmI&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=51), another unsupervised learning technique called [sparse coding](https://www.youtube.com/watch?v=7a0_iEruGoM&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=60) (which we also skipped due to time limits) and [computer vision](https://www.youtube.com/watch?v=rxKrCa4bg1I&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=69) (with strong emphasis on convolutional networks). The last chapter is about [natural language processing](https://www.youtube.com/watch?v=OzZIOiMVUyM&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=79).

![Denoising autoencoders](/public/2015-07-30/denoising-autoencoder-slide.png "A slide on denoising autoencoders from Hugo Larochelle's video course")

The lectures contain lots of references to papers and demonstrations, the slides are full of visualizations and graphs, and, last but not least, Hugo kindly answers all questions posed in the comments of Youtube videos. After watching the chapter on convolutional networks we decided to apply what we learned on some computer vision contest. We looked at the list of active competitions on Kaggle and the only one related to computer vision was the [Diabetic retinopathy detection contest](https://www.kaggle.com/c/diabetic-retinopathy-detection). It seemed to be very hard as a first project in neural nets, but we decided to try. We'll describe our experience with this contest in the next post.
